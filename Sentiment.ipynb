{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Model\n",
    "Weight and Notebook at https://github.com/Ayushk4/JuliaCon20_Talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, BSON, WordTokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct SentimentModel{WE, L1, L2, D}\n",
    "    vocab_dict::Dict{String,Integer} # Dict that maps words to indices in W_word_Embed\n",
    "    W_Embed::WE # Fine Tuned GloVe Embeddings\n",
    "    lstm1::L1 # Forward LSTM 1\n",
    "    lstm2::L2 # Forward LSTM 2\n",
    "    d::D # Classifier\n",
    "    UNK_Word_idx::Integer\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tokenize_and_index(model, sentence::String)\n",
    "    convert_to_oh(word) = Flux.unsqueeze(Flux.onehot(get(model.vocab_dict, word, get(model.vocab_dict,\n",
    "                                        lowercase(word), model.UNK_Word_idx)), 1:length(model.vocab_dict)), 1)\n",
    "    tokens = WordTokenizers.nltk_word_tokenize(sentence)\n",
    "    ohs = convert_to_oh.(tokens)\n",
    "    return ohs, tokens\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (m::SentimentModel)(token_onehot)\n",
    "    Flux.reset!(m.lstm1)\n",
    "    Flux.reset!(m.lstm2)\n",
    "    embed(x) = m.W_Embed * x'\n",
    "    e = embed.(token_onehot)\n",
    "    w = @. m.lstm2(m.lstm1(e))\n",
    "    logits = m.d(m.lstm2.state[1]) # We just need the last hidden state of the LSTM\n",
    "    return Flux.softmax(logits), logits\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"sentiment_weights.bson\" trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"This package is maintained by John Doe.\",\n",
    "             \"This package is nicely maintained by John Doe.\",\n",
    "             \"This package is poorly maintained by John Doe.\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sentences\n",
    "    println()\n",
    "    ohs, tokens = tokenize_and_index(trained_model, sent)\n",
    "    println(sent, \" => \", tokens)\n",
    "    scores, logits = trained_model(ohs)\n",
    "    if score\n",
    "    println(\"Positive Sentiment score: \", scores, logits)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_sentiment(sent)\n",
    "    ohs, tokens = tokenize_and_index(trained_model, sent)\n",
    "    scores, logits = trained_model(ohs)\n",
    "    if scores[1] > 0.5\n",
    "        println(\"\\\"\", sent, \"\\\" has 'positive' sentiment with score: \", scores[1])\n",
    "    else\n",
    "        println(\"\\\"\", sent, \"\\\" has 'negative' sentiment with score: \", scores[2])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(sentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
