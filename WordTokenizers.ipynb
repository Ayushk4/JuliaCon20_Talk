{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordTokenizers.jl\n",
    "(Disclaimer: The package name is misleading, it may also provide you sentence and subword tokenizers.)\n",
    "\n",
    "https://github.com/JuliaText/WordTokenizers.jl\n",
    "\n",
    "Notebooks at https://github.com/Ayushk4/JuliaCon20_Talk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using WordTokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Tokenizer (Sentence Splitters / segmenters)\n",
    "Uses a rule based approach with a large list of exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dr. Jane Doe says leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about 900 kg). Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. The Flatback turtle is found solely on the northerncoast of Australia.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Dr. Jane Doe says leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about 900 kg). Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide. The Flatback turtle is found solely on the northerncoast of Australia.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{SubString{String},1}:\n",
       " \"Dr. Jane Doe says leatherback sea turtle is the largest, measuring six or seven feet (2 m) in length at maturity, and three to five feet (1 to 1.5 m) in width, weighing up to 2000 pounds (about 900 kg).\"\n",
       " \"Most other species are smaller, being two to four feet in length (0.5 to 1 m) and proportionally less wide.\"                                                                                               \n",
       " \"The Flatback turtle is found solely on the northerncoast of Australia.\"                                                                                                                                    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sentences(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenizers\n",
    "These Tokenizers assume that Sentence Splitting has already been done.\n",
    "- Poorman's tokenizer\n",
    "- Punctuation space tokenize\n",
    "- Penn Tokenizer\n",
    "- Improved Penn Tokenizer\n",
    "- NLTK Word tokenizer\n",
    "- Reversible Tokenizer\n",
    "- TokTok Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordTokenizers for high-speed tokenization\n",
    "# 1. nltk_word_tokenizer\n",
    "# 2. multilingual toktok_tokenizer\n",
    "# 3. tweet_tokenizer\n",
    "# 4. plug in external tokenizers, 7+ tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@JohnDoe says: Well, we couldn't have this cliche-ridden, \\\"Touched by Angel\\\" to check out #GitHub https://github.com.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"@JohnDoe says: Well, we couldn't have this cliche-ridden, \\\"Touched by Angel\\\" to check out #GitHub https://github.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16-element Array{SubString{String},1}:\n",
       " \"@JohnDoe\"           \n",
       " \"says:\"              \n",
       " \"Well,\"              \n",
       " \"we\"                 \n",
       " \"couldn't\"           \n",
       " \"have\"               \n",
       " \"this\"               \n",
       " \"cliche-ridden,\"     \n",
       " \"\\\"Touched\"          \n",
       " \"by\"                 \n",
       " \"Angel\\\"\"            \n",
       " \"to\"                 \n",
       " \"check\"              \n",
       " \"out\"                \n",
       " \"#GitHub\"            \n",
       " \"https://github.com.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@\", \"JohnDoe\", \"says\", \":\", \"Well\", \",\", \"we\", \"could\", \"n't\", \"have\", \"this\", \"cliche-ridden\", \",\", \"``\", \"Touched\", \"by\", \"Angel\", \"''\", \"to\", \"check\", \"out\", \"#\", \"GitHub\", \"https\", \":\", \"/\", \"/\", \"github.com\", \".\"]"
     ]
    }
   ],
   "source": [
    "# Modified version of NLTK's tokenizer\n",
    "print(WordTokenizers.nltk_word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@\", \"JohnDoe\", \"says\", \":\", \"Well\", \",\", \"we\", \"couldn\", \"'\", \"t\", \"have\", \"this\", \"cliche-ridden\", \",\", \"\\\"\", \"Touched\", \"by\", \"Angel\", \"\\\"\", \"to\", \"check\", \"out\", \"#\", \"GitHub\", \"https://github.com\", \".\"]"
     ]
    }
   ],
   "source": [
    "# Modified version of Jon Safari's toktok tokenizer\n",
    "print(WordTokenizers.toktok_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@JohnDoe\", \"says\", \":\", \"Well\", \",\", \"we\", \"couldn't\", \"have\", \"this\", \"cliche-ridden\", \",\", \"\\\"\", \"Touched\", \"by\", \"Angel\", \"\\\"\", \"to\", \"check\", \"out\", \"#GitHub\", \"https://github.com\", \".\"]"
     ]
    }
   ],
   "source": [
    "# Modified version of NLTK's casual tokenizer\n",
    "print(WordTokenizers.tweet_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@\", \"JohnDoe\", \"dice\", \":\", \"Bueno\", \",\", \"no\", \"podríamos\", \"tener\", \"este\", \"cliché\", \",\", \"\\\"\", \"Tocado\", \"por\", \"Angel\", \"\\\"\", \"para\", \"ver\", \"#\", \"GitHub\", \"https://github.com\", \".\"]"
     ]
    }
   ],
   "source": [
    "# Obtained using google translate\n",
    "spanish_text = \"@JohnDoe dice: Bueno, no podríamos tener este cliché, \\\"Tocado por Angel\\\" para ver #GitHub https://github.com.\"\n",
    "print(WordTokenizers.toktok_tokenize(spanish_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@\", \"जॉनडे\", \"कहते\", \"हैं\", \":\", \"ठीक\", \"है\", \",\", \"हम\", \"इस\", \"क्लिज्ड\", \",\", \"\\\"\", \"एंजेल\", \"द्वारा\", \"छुआ\", \"\\\"\", \"#\", \"GitHub\", \"https://github.com\", \"की\", \"जांच\", \"कर\", \"सकते\", \"हैं\", \"।\"]"
     ]
    }
   ],
   "source": [
    "# Obtained using google translate\n",
    "hindi_text = \"@ जॉनडे कहते हैं: ठीक है, हम इस क्लिज्ड, \\\"एंजेल द्वारा छुआ\\\" #GitHub https://github.com की जांच कर सकते हैं।\"\n",
    "print(WordTokenizers.toktok_tokenize(hindi_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token-Buffer API\n",
    "TokenBuffer API and supporting utility lexers enables high-speed non-regex based tokenization.\n",
    "\n",
    "TokenBuffer turns a string into a readable stream, used for building tokenizers. Utility lexers such as spaces and number read characters from the stream and into an array of tokens.\n",
    "\n",
    "Lexers return true or false to indicate whether they matched in the input stream and therefore can be combined easily - \n",
    "`spacesornumber(ts) = spaces(ts) || number(ts)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "using WordTokenizers: TokenBuffer, isdone, character, spaces, nltk_url1, nltk_url2, nltk_phonenumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{String,1}:\n",
       " \"A\"                                              \n",
       " \"url\"                                            \n",
       " \"https://github.com/JuliaText/WordTokenizers.jl/\"\n",
       " \"and\"                                            \n",
       " \"phonenumber\"                                    \n",
       " \"+0 (987) - 2344321\"                             \n",
       " \"#MeaningLess\"                                   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_tok(input)\n",
    "   urls(ts) = nltk_url1(ts) || nltk_url2(ts)\n",
    "\n",
    "   ts = TokenBuffer(input)\n",
    "   while !isdone(ts)\n",
    "       spaces(ts) && continue\n",
    "       urls(ts) ||\n",
    "       nltk_phonenumbers(ts) ||\n",
    "       character(ts)\n",
    "   end\n",
    "   return ts.tokens\n",
    "end\n",
    "\n",
    "my_tok(\"A url https://github.com/JuliaText/WordTokenizers.jl/ and phonenumber +0 (987) - 2344321 #MeaningLess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical (and subword) Tokenizers\n",
    "More on this later.\n",
    "\n",
    "\n",
    "----------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
